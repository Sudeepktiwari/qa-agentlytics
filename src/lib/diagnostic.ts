import OpenAI from "openai";
import { getDb } from "./mongo";
import { querySimilarChunks } from "./chroma";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

export async function autoGenerateDiagnosticAnswers(adminId: string) {
  console.log(`[Diagnostic] Starting post-crawl generation for ${adminId}...`);
  try {
    const db = await getDb();
    const summariesCollection = db.collection("structured_summaries");

    // 1. Fetch all summaries
    const summaries = await summariesCollection.find({ adminId }).toArray();
    if (!summaries.length) {
      console.log(`[Diagnostic] No structured summaries found for ${adminId}`);
      return;
    }

    // 2. Collect all options
    const allOptionsMap = new Map<
      string,
      { label: string; workflow: string }
    >();
    summaries.forEach((s) => {
      s.structuredSummary?.sections?.forEach((sec: any) => {
        [...(sec.leadQuestions || []), ...(sec.salesQuestions || [])].forEach(
          (q: any) => {
            q.options?.forEach((o: any) => {
              if (o.label && o.workflow) {
                const key = `${o.label}::${o.workflow}`;
                allOptionsMap.set(key, {
                  label: o.label,
                  workflow: o.workflow,
                });
              }
            });
          },
        );
      });
    });

    const uniqueOptions = Array.from(allOptionsMap.values());
    console.log(
      `[Diagnostic] Found ${uniqueOptions.length} unique options to process.`,
    );

    // 3. Process with concurrency (Batch of 5)
    const results = new Map<string, string>(); // key -> answer

    const processOption = async (opt: { label: string; workflow: string }) => {
      try {
        // A. Get Embedding for the option label to find relevant content
        const embResp = await openai.embeddings.create({
          model: "text-embedding-3-small",
          input: opt.label,
          dimensions: 1024,
        });
        const vector = embResp.data[0].embedding;

        // B. Get Context from vector DB
        const chunks = await querySimilarChunks(vector, 3, adminId);
        const contextText = chunks.map((c) => c.text).join("\n---\n");

        // C. Generate Answer using strict template
        const answer = await generateSingleDiagnosticAnswer(
          opt.label,
          opt.workflow,
          contextText,
        );
        results.set(`${opt.label}::${opt.workflow}`, answer);
      } catch (e) {
        console.error(`Error processing option ${opt.label}:`, e);
      }
    };

    // Run in batches
    const BATCH_SIZE = 5;
    for (let i = 0; i < uniqueOptions.length; i += BATCH_SIZE) {
      const batch = uniqueOptions.slice(i, i + BATCH_SIZE);
      await Promise.all(batch.map(processOption));
      console.log(
        `[Diagnostic] Processed ${Math.min(i + BATCH_SIZE, uniqueOptions.length)}/${uniqueOptions.length}`,
      );
    }

    // 4. Update Database
    let updatedCount = 0;
    for (const summary of summaries) {
      let modified = false;
      const sections = summary.structuredSummary?.sections;
      if (!sections) continue;

      sections.forEach((sec: any) => {
        [...(sec.leadQuestions || []), ...(sec.salesQuestions || [])].forEach(
          (q: any) => {
            q.options?.forEach((o: any) => {
              const key = `${o.label}::${o.workflow}`;
              if (results.has(key)) {
                o.diagnostic_answer = results.get(key);
                modified = true;
              }
            });
          },
        );
      });

      if (modified) {
        await summariesCollection.updateOne(
          { _id: summary._id },
          {
            $set: {
              "structuredSummary.sections": sections,
              diagnosticGeneratedAt: new Date(),
            },
          },
        );
        updatedCount++;
      }
    }
    console.log(
      `[Diagnostic] Completed updates for ${updatedCount} summaries.`,
    );
  } catch (err) {
    console.error("[Diagnostic] Critical error in post-crawl generation:", err);
  }
}

export async function generateSingleDiagnosticAnswer(
  label: string,
  workflow: string,
  context: string,
) {
  try {
    const prompt = `
SYSTEM:
Write a diagnostic answer based on the workflow type.
You MUST use the provided WEBSITE CONTEXT to make the answer specific to the business domain.

RULES:
Follow the correct template based on the workflow:
- validation_path → Reflect that the user’s choice indicates stability/low friction. Explain why that matters (momentum preserved). Mention “Calendly supports this motion” conceptually (no features).
- optimization_workflow → Reflect the friction (manual steps, delays, uncertainty). Explain the consequences (intent decay, slow response, leakage). Explain how Calendly resolves friction conceptually (not features). Validate the fit.
- diagnostic_education → Reflect uncertainty / incomplete visibility. Explain why this creates hidden loss. Explain how Calendly creates clarity. Validate fit.
- sales_alert → Reflect severity and risk. Explain the consequence (silent drop-off / leakage). Explain conceptual resolution. Validate fit.

CRITICAL: 
- No features. No CTAs.
- Use the WEBSITE CONTEXT to ground your answer in the customer's actual business domain.
- Keep it concise (2-3 sentences max).

WEBSITE CONTEXT:
${context}

INPUT:
label: ${label}
workflow: ${workflow}

OUTPUT:
Return ONLY the diagnostic answer string (no JSON, no quotes around the whole string unless part of the text).
`;

    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [{ role: "user", content: prompt }],
      temperature: 0.3,
    });

    return response.choices[0]?.message?.content?.trim() || "";
  } catch (e) {
    console.error("Error generating single diagnostic answer:", e);
    return "";
  }
}
