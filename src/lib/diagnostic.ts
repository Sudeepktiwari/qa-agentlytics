import OpenAI from "openai";
import { getDb } from "./mongo";
import { querySimilarChunks } from "./chroma";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

export async function autoGenerateDiagnosticAnswers(
  adminId: string,
  filterUrl?: string,
) {
  console.log(
    `[Diagnostic] Starting post-crawl generation for ${adminId}${
      filterUrl ? ` (URL: ${filterUrl})` : ""
    }...`,
  );
  try {
    const db = await getDb();
    const summariesCollection = db.collection("structured_summaries");

    // 1. Fetch summaries (filter by URL if provided)
    const query: any = { adminId };
    if (filterUrl) {
      query.url = filterUrl;
    }
    const summaries = await summariesCollection.find(query).toArray();
    if (!summaries.length) {
      console.log(
        `[Diagnostic] No structured summaries found for ${adminId}${
          filterUrl ? ` matching ${filterUrl}` : ""
        }`,
      );
      return;
    }

    // 2. Collect all options
    const allOptionsMap = new Map<
      string,
      { label: string; workflow: string }
    >();
    summaries.forEach((s) => {
      s.structuredSummary?.sections?.forEach((sec: any) => {
        [...(sec.leadQuestions || []), ...(sec.salesQuestions || [])].forEach(
          (q: any) => {
            q.options?.forEach((o: any) => {
              if (o.label && o.workflow) {
                const key = `${o.label}::${o.workflow}`;
                allOptionsMap.set(key, {
                  label: o.label,
                  workflow: o.workflow,
                });
              }
            });
          },
        );
      });
    });

    const uniqueOptions = Array.from(allOptionsMap.values());
    console.log(
      `[Diagnostic] Found ${uniqueOptions.length} unique options to process.`,
    );

    // 3. Process with concurrency (Batch of 5)
    const results = new Map<string, string>(); // key -> answer

    const processOption = async (opt: { label: string; workflow: string }) => {
      try {
        // A. Get Embedding for the option label to find relevant content
        const embResp = await openai.embeddings.create({
          model: "text-embedding-3-small",
          input: opt.label,
          dimensions: 1024,
        });
        const vector = embResp.data[0].embedding;

        // B. Get Context from vector DB
        const chunks = await querySimilarChunks(vector, 3, adminId);
        const contextText = chunks.map((c) => c.text).join("\n---\n");

        // C. Generate Answer using strict template
        const answer = await generateSingleDiagnosticAnswer(
          opt.label,
          opt.workflow,
          contextText,
        );
        results.set(`${opt.label}::${opt.workflow}`, answer);
      } catch (e) {
        console.error(`Error processing option ${opt.label}:`, e);
      }
    };

    // Run in batches
    const BATCH_SIZE = 5;
    for (let i = 0; i < uniqueOptions.length; i += BATCH_SIZE) {
      const batch = uniqueOptions.slice(i, i + BATCH_SIZE);
      await Promise.all(batch.map(processOption));
      console.log(
        `[Diagnostic] Processed ${Math.min(i + BATCH_SIZE, uniqueOptions.length)}/${uniqueOptions.length}`,
      );
    }

    // 4. Update Database
    let updatedCount = 0;
    for (const summary of summaries) {
      let modified = false;
      const sections = summary.structuredSummary?.sections;
      if (!sections) continue;

      sections.forEach((sec: any) => {
        [...(sec.leadQuestions || []), ...(sec.salesQuestions || [])].forEach(
          (q: any) => {
            q.options?.forEach((o: any) => {
              const key = `${o.label}::${o.workflow}`;
              if (results.has(key)) {
                o.diagnostic_answer = results.get(key);
                modified = true;
              }
            });
          },
        );
      });

      if (modified) {
        await summariesCollection.updateOne(
          { _id: summary._id },
          {
            $set: {
              "structuredSummary.sections": sections,
              diagnosticGeneratedAt: new Date(),
            },
          },
        );
        updatedCount++;
      }
    }
    console.log(
      `[Diagnostic] Completed updates for ${updatedCount} summaries.`,
    );
  } catch (err) {
    console.error("[Diagnostic] Critical error in post-crawl generation:", err);
  }
}

export async function generateSingleDiagnosticAnswer(
  label: string,
  workflow: string,
  context: string,
) {
  try {
    const prompt = `
SYSTEM:
You are an expert consultant engaging with a potential client. They just selected an option, and you need to provide a diagnostic insight that demonstrates value.
Write your response as a professional, direct message to the user. Use "you" and "your".

RULES:
- Tone: Professional, consultative, value-driven. suitable for client communication.
- Follow the correct template based on the workflow:
  - validation_path → Validate their strong position. Suggest how they can leverage this stability to scale or optimize further using the platform. Focus on "what's next" for growth.
  - optimization_workflow → Acknowledge the process friction. Explain the specific business impact (e.g., lost revenue, efficiency gaps). Clearly state how the platform automates or resolves this.
  - diagnostic_education → Address the visibility gap. Explain why knowing this data is critical for decision-making. Explain how the platform provides this specific intelligence.
  - sales_alert → Address the high-stakes nature of the problem. Explain the cost of inaction. Briefly explain how the platform mitigates this risk immediately.

CRITICAL: 
- FOCUS ON VALUE: Explain HOW the platform helps.
- You MAY mention relevant high-level capabilities or features if they solve the problem.
- Use the WEBSITE CONTEXT to ground your answer in the customer's specific business domain.
- Keep it concise (2-3 sentences max).
- Avoid generic phrases like "It looks like your choice indicates...". Be direct.

WEBSITE CONTEXT:
${context}

INPUT:
label: ${label}
workflow: ${workflow}

OUTPUT:
Return ONLY the diagnostic answer string (no JSON, no quotes around the whole string unless part of the text).
`;

    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [{ role: "user", content: prompt }],
      temperature: 0.3,
    });

    return response.choices[0]?.message?.content?.trim() || "";
  } catch (e) {
    console.error("Error generating single diagnostic answer:", e);
    return "";
  }
}
